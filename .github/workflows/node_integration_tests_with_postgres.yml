name: Integration & E2E Tests

on:
  workflow_call:
    inputs:
      node_version_file:
        description: "setup-node reads Node version from here"
        required: false
        type: string
        default: ".nvmrc"

permissions:
  contents: read

jobs:
  integration-tests:
    name: integration tests
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports: [ "5432:5432" ]
        options: >-
          --health-cmd="pg_isready -U postgres -d postgres"
          --health-interval=5s --health-timeout=5s --health-retries=20
      localstack:
        image: localstack/localstack:latest
        ports: [ "4566:4566" ]
        env:
          SERVICES: s3,sqs,sns
      redis:
        image: redis:7-alpine
        ports: [ "6379:6379" ]

    env:
      AWS_DEFAULT_REGION: eu-west-2
      AWS_ACCESS_KEY_ID: foobar
      AWS_SECRET_ACCESS_KEY: foobar
      LS: http://127.0.0.1:4566

    steps:
      - uses: actions/checkout@v4

      - name: Start WireMock (global response templating)
        run: |
          docker run -d --name wiremock-ci \
            -p 8099:8080 \
            wiremock/wiremock:2.35.0 \
            --port 8080 --global-response-templating
          # wait until ready
          for i in {1..30}; do
            curl -fsS "http://127.0.0.1:8099/__admin" >/dev/null && break
            echo "Waiting for WireMock... ($i/30)"; sleep 2
          done
          # quick proof that templating is ON (this endpoint exists in v2.35 but doesn't reflect global flag,
          # so we'll do a live render check right after mappings are loaded)

      - name: Wait for services
        run: |
          for i in {1..60}; do pg_isready -h 127.0.0.1 -p 5432 -U postgres -d postgres && break; sleep 1; done
          curl -sfS --retry 20 --retry-connrefused --retry-delay 2 "$LS/_localstack/health" || exit 1
          curl -sfS --retry 20 --retry-connrefused --retry-delay 2 "http://127.0.0.1:8099/__admin" || exit 1
          for i in {1..60}; do (echo > /dev/tcp/127.0.0.1/6379) >/dev/null 2>&1 && break; sleep 1; done

      - name: Install jq & psql client
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq postgresql-client

      - name: Setup AWS CLI
        run: |
          python3 -m pip install --user --upgrade pip
          python3 -m pip install --user "awscli==1.*"
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"

      - name: Create sample dashboard file (used for uploads)
        run: printf 'dashboard' > dashboard-file.txt

      - name: Seed LocalStack (S3 + SQS)
        run: |
          set -euo pipefail
          aws --endpoint-url="$LS" sqs create-queue --queue-name audit_event_queue || true
          aws --endpoint-url="$LS" s3api create-bucket \
            --bucket wmt-web \
            --region "$AWS_DEFAULT_REGION" \
            --create-bucket-configuration LocationConstraint="$AWS_DEFAULT_REGION" || true
          for ts in 20210729062147 20210730062147 20210801062147 20210802062147; do
            aws --endpoint-url="$LS" s3api put-object \
              --bucket wmt-web \
              --key generated-dashboards/dashboard_${ts}.txt \
              --body dashboard-file.txt
          done

      - name: Start hmpps_workload container
        run: |
          docker run -d --name hmpps_workload \
            --add-host=host.docker.internal:host-gateway \
            -e SPRING_PROFILES_ACTIVE=dev,docker \
            -e DATABASE_USERNAME=postgres \
            -e DATABASE_PASSWORD=postgres \
            -e DATABASE_ENDPOINT=host.docker.internal:5432 \
            -e HMPPS_SQS_LOCALSTACK_URL=http://host.docker.internal:4566 \
            ghcr.io/ministryofjustice/hmpps-workload:latest \
            /bin/sh -lc 'sleep 10 && java -javaagent:/app/agent.jar -jar /app/app.jar'

      - name: Wait for DB schema
        env: { PGPASSWORD: postgres }
        run: |
          for i in {1..120}; do
            psql -h 127.0.0.1 -U postgres -d postgres -tAc \
              "SELECT 1 FROM information_schema.tables WHERE table_name='flyway_schema_history'" | grep -q 1 && exit 0
            sleep 2
          done
          echo "Schema not ready in time"; docker logs hmpps_workload || true; exit 1

      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: ${{ inputs.node_version_file }}

      - name: Install deps
        run: npm ci --no-audit

      - name: Run integration tests
        env:
          DATABASE_SERVER: 127.0.0.1
          DATABASE_USERNAME: postgres
          DATABASE_PASSWORD: postgres
          DATABASE: postgres
          DATABASE_PORT: "5432"
          DATABASE_SSL: "false"
        run: npm run integration-test

  e2e-tests:
    name: e2e tests
    needs: integration-tests
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports: [ "5432:5432" ]
        options: >-
          --health-cmd="pg_isready -U postgres -d postgres"
          --health-interval=5s --health-timeout=5s --health-retries=20
      localstack:
        image: localstack/localstack:latest
        ports: [ "4566:4566" ]
        env:
          SERVICES: s3,sqs,sns
      # REMOVE wiremock service here
      redis:
        image: redis:7-alpine
        ports: [ "6379:6379" ]

    env:
      AWS_DEFAULT_REGION: eu-west-2
      AWS_ACCESS_KEY_ID: foobar
      AWS_SECRET_ACCESS_KEY: foobar
      LS: http://127.0.0.1:4566

      APP_PORT: "3000"
      BASE_URL: http://127.0.0.1:3000
      WIREMOCK_URL: http://127.0.0.1:8099
      CHROME_BIN: /usr/bin/google-chrome

    steps:
      - uses: actions/checkout@v4

      # NEW: start WireMock with response templating enabled (exactly like CircleCI)
      - name: Start WireMock (global response templating)
        run: |
          docker run -d --name wiremock-ci \
            -p 8099:8080 \
            wiremock/wiremock:2.35.0 \
            --port 8080 --global-response-templating
          # wait until ready
          for i in {1..30}; do
            curl -fsS "http://127.0.0.1:8099/__admin" >/dev/null && break
            echo "Waiting for WireMock... ($i/30)"; sleep 2
          done
          # quick proof that templating is ON (this endpoint exists in v2.35 but doesn't reflect global flag,
          # so we'll do a live render check right after mappings are loaded)

      - name: Post critical Auth stubs (authorize/token/health)
        env:
          BASE_URL: ${{ env.BASE_URL }}
          WIREMOCK_URL: ${{ env.WIREMOCK_URL }}
        run: |
          set -euo pipefail
          post() {
            curl -fsS -X POST "$WIREMOCK_URL/__admin/mappings" \
              -H 'Content-Type: application/json' \
              -d "$1" >/dev/null
          }

          # 200 health
          post '{
            "request": { "method":"GET", "url":"/auth/health/ping" },
            "response": { "status":200, "jsonBody":{ "status":"UP" } }
          }'

          # token endpoint
          post '{
            "request": { "method":"POST", "url":"/auth/oauth/token" },
            "response": {
              "status":200,
              "headers": { "Content-Type":"application/json" },
              "jsonBody": {
                "access_token":"***", "token_type":"bearer", "user_name":"USER1",
                "expires_in":599, "scope":"read", "internalUser":true
              }
            }
          }'

          # authorize -> 302 to redirect_uri with code & state (uses response-template)
          post '{
            "priority": 1,
            "request": {
              "method":"GET",
              "urlPath":"/auth/oauth/authorize",
              "queryParameters": {
                "response_type": { "equalTo":"code" },
                "redirect_uri": { "matches":".*" },
                "state": { "matches":".*" },
                "client_id": { "equalTo":"workload-measurement-ui" }
              }
            },
            "response": {
              "status":302,
              "headers": {
                "Location": "{{request.query.redirect_uri}}?code=codexxxx&state={{request.query.state}}"
              },
              "transformers": ["response-template"]
            }
          }'

          # prove theyâ€™re loaded and matching
          echo -n "Mappings now: "
          curl -s "$WIREMOCK_URL/__admin/mappings" | jq '.mappings | length'
          echo
          echo "Authorize probe (should be 302 with Location to ${BASE_URL}/sign-in/callback):"
          curl -s -i "$WIREMOCK_URL/auth/oauth/authorize?client_id=workload-measurement-ui&redirect_uri=${BASE_URL}/sign-in/callback&response_type=code&state=xyz" | head -n 20


      - name: Wait for other services
        run: |
          for i in {1..60}; do pg_isready -h 127.0.0.1 -p 5432 -U postgres -d postgres && break; sleep 1; done
          curl -sfS --retry 30 --retry-connrefused --retry-delay 2 "$LS/_localstack/health" || exit 1
          for i in {1..60}; do (echo > /dev/tcp/127.0.0.1/6379) >/dev/null 2>&1 && break; sleep 1; done

      - name: Setup AWS CLI + jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq
          python3 -m pip install --user --upgrade pip
          python3 -m pip install --user "awscli==1.*"
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"

      - name: Seed LocalStack (queue + sample dashboards)
        run: |
          set -euo pipefail
          aws --endpoint-url="$LS" sqs create-queue --queue-name audit_event_queue || true
          aws --endpoint-url="$LS" s3api create-bucket \
            --bucket wmt-web \
            --region "$AWS_DEFAULT_REGION" \
            --create-bucket-configuration LocationConstraint="$AWS_DEFAULT_REGION" || true
          printf 'dashboard' > dashboard-file.txt
          for ts in 20210729062147 20210730062147 20210731062147 20210801062147 20210802062147; do
            aws --endpoint-url="$LS" s3api put-object \
              --bucket wmt-web \
              --key generated-dashboards/dashboard_${ts}.txt \
              --body dashboard-file.txt
          done

      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: ${{ inputs.node_version_file }}

      - name: Install deps
        run: npm ci --no-audit

      - name: Install Google Chrome (for WDIO)
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y wget gpg
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo gpg --dearmor -o /usr/share/keyrings/google-linux-signing-keyring.gpg
          echo "deb [arch=amd64 signed-by=/usr/share/keyrings/google-linux-signing-keyring.gpg] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list >/dev/null
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          google-chrome --version

      - name: Install psql client
        run: |
          sudo apt-get update -y
          sudo apt-get install -y postgresql-client

      - name: Start hmpps_workload container
        run: |
          docker run -d --name hmpps_workload \
            --add-host=host.docker.internal:host-gateway \
            -e SPRING_PROFILES_ACTIVE=dev,docker \
            -e DATABASE_USERNAME=postgres \
            -e DATABASE_PASSWORD=postgres \
            -e DATABASE_ENDPOINT=host.docker.internal:5432 \
            -e HMPPS_SQS_LOCALSTACK_URL=http://host.docker.internal:4566 \
            ghcr.io/ministryofjustice/hmpps-workload:latest \
            /bin/sh -lc 'sleep 10 && java -javaagent:/app/agent.jar -jar /app/app.jar'

      - name: Wait for DB schema
        env: { PGPASSWORD: postgres }
        run: |
          for i in {1..120}; do
            psql -h 127.0.0.1 -U postgres -d postgres -tAc \
              "SELECT 1 FROM information_schema.tables WHERE table_name='flyway_schema_history'" | grep -q 1 && exit 0
            echo "Waiting for Flyway schema... ($i/120)"
            sleep 2
          done
          echo "Schema not ready in time"; docker logs hmpps_workload || true; exit 1

      - name: Build assets
        run: npm run build

      - name: Start app (direct)
        env:
          WMT_WEB_APPLICATION_SECRET: ci-dev-secret
          SESSION_SECRET: ci-session-secret
          WMT_LIVE_DB_SERVER: 127.0.0.1
          WMT_LIVE_DB_NAME: postgres
          WMT_LIVE_DB_USERNAME: postgres
          WMT_LIVE_DB_PASSWORD: postgres
          WMT_HISTORY_DB_SERVER: 127.0.0.1
          WMT_HISTORY_DB_PORT: "5432"
          WMT_HISTORY_DB_NAME: postgres
          WMT_HISTORY_DB_USERNAME: postgres
          WMT_HISTORY_DB_PASSWORD: postgres
          REDIS_HOST: 127.0.0.1
          REDIS_PORT: "6379"
          REDIS_URL: redis://127.0.0.1:6379
          HMPPS_AUTH_URL: http://127.0.0.1:8099/auth
          HMPPS_AUTH_EXTERNAL_URL: http://127.0.0.1:8099/auth
          MANAGE_USERS_SERVICE_URL: http://127.0.0.1:8099
          ALLOCATIONS_SERVICE_URL: http://127.0.0.1:8099
          USER_PREFERENCE_SERVICE_URL: http://127.0.0.1:8099
          TOKEN_VERIFICATION_API_URL: http://127.0.0.1:8099
          TOKEN_VERIFICATION_ENABLED: "true"
          INGRESS_URL: http://127.0.0.1:3000
          PORT: 3000
        run: |
          set -euo pipefail
          export $(grep -v '^\s*#' feature.env | xargs) || true
          nohup node app/bin/www > /tmp/app.log 2>&1 &
          for i in {1..120}; do
            code=$(curl -s -o /dev/null -w "%{http_code}" "http://127.0.0.1:3000/" || echo "000")
            if [ "$code" = "200" ] || [ "$code" = "302" ]; then
              echo "App ready at http://127.0.0.1:3000 ($code)"; break
            fi
            echo "Waiting for app... ($i/120)"; sleep 2
          done
          tail -n 200 /tmp/app.log || true

      - name: Load WireMock mappings (your script)
        run: npm run post-wiremock-mappings

      - name: Augment WireMock (no reset) - add high-priority /auth/authorize + ensure health stubs
        env:
          BASE_URL: ${{ env.BASE_URL }}
          WIREMOCK_URL: ${{ env.WIREMOCK_URL }}
        run: |
          set -euo pipefail

          post() {
            curl -fsS -X POST "$WIREMOCK_URL/__admin/mappings" \
              -H 'Content-Type: application/json' \
              -d "$1" >/dev/null
          }

          # Keep your repo mappings, just add a high-priority authorize override that always 302s
          post '{
            "priority": 1,
            "request": { "method":"GET", "urlPattern": "/auth/oauth/authorize.*" },
            "response": {
              "status": 302,
              "headers": {
                "Location": "{{request.query.redirect_uri}}?code=codexxxx&state={{request.query.state}}"
              },
              "transformers": ["response-template"]
            }
          }'

          # Ensure BOTH health endpoints exist (your app hits /health/ping; hmppsAuth hits /auth/health/ping)
          post '{ "priority":1, "request":{"method":"GET","url":"/health/ping"}, "response":{"status":200,"jsonBody":{"status":"UP"}} }'
          post '{ "priority":1, "request":{"method":"GET","url":"/auth/health/ping"}, "response":{"status":200,"jsonBody":{"status":"UP"}} }'

          # (Optional, but harmless) ensure token endpoint too
          post '{
            "priority": 1,
            "request": { "method":"POST", "url":"/auth/oauth/token" },
            "response": {
              "status":200,
              "headers": { "Content-Type":"application/json;charset=UTF-8" },
              "jsonBody": {
                "access_token":"***", "token_type":"bearer",
                "user_name":"USER1", "expires_in":599,
                "scope":"read", "internalUser":true
              }
            }
          }'

          echo -n "Total mappings: "
          curl -s "$WIREMOCK_URL/__admin/mappings" | jq '.mappings | length'

          echo "Authorize probe (expect 302 to ${BASE_URL}/sign-in/callback):"
          curl -s -i "$WIREMOCK_URL/auth/oauth/authorize?client_id=workload-measurement-ui&redirect_uri=${BASE_URL}/sign-in/callback&response_type=code&state=xyz" | head -n 20


      - name: Sanity check authorize redirect renders
        run: |
          curl -s -i "http://127.0.0.1:8099/auth/oauth/authorize?client_id=workload-measurement-ui&redirect_uri=${BASE_URL}/sign-in/callback&response_type=code&state=xyz" | head -n 20

      - name: Build assets
        run: npm run build

      - name: Start app (direct; robust wait; 127.0.0.1 everywhere)
        env:
          WMT_WEB_APPLICATION_SECRET: ci-dev-secret
          SESSION_SECRET: ci-session-secret
          WMT_LIVE_DB_SERVER: 127.0.0.1
          WMT_LIVE_DB_NAME: postgres
          WMT_LIVE_DB_USERNAME: postgres
          WMT_LIVE_DB_PASSWORD: postgres
          WMT_HISTORY_DB_SERVER: 127.0.0.1
          WMT_HISTORY_DB_PORT: "5432"
          WMT_HISTORY_DB_NAME: postgres
          WMT_HISTORY_DB_USERNAME: postgres
          WMT_HISTORY_DB_PASSWORD: postgres
          REDIS_HOST: 127.0.0.1
          REDIS_PORT: "6379"
          REDIS_URL: redis://127.0.0.1:6379
          HMPPS_AUTH_URL: http://127.0.0.1:8099/auth
          HMPPS_AUTH_EXTERNAL_URL: http://127.0.0.1:8099/auth
          MANAGE_USERS_SERVICE_URL: http://127.0.0.1:8099
          ALLOCATIONS_SERVICE_URL: http://127.0.0.1:8099
          USER_PREFERENCE_SERVICE_URL: http://127.0.0.1:8099
          TOKEN_VERIFICATION_API_URL: http://127.0.0.1:8099
          TOKEN_VERIFICATION_ENABLED: "true"
          INGRESS_URL: http://127.0.0.1:3000
          PORT: 3000
        run: |
          set -euo pipefail
          export $(grep -v '^\s*#' feature.env | xargs) || true
          nohup node app/bin/www > /tmp/app.log 2>&1 &
          ready=""
          for i in {1..120}; do
            code=$(curl -s -o /dev/null -w "%{http_code}" "http://127.0.0.1:3000/" || echo "000")
            if [ "$code" = "200" ] || [ "$code" = "302" ]; then
              echo "App ready at http://127.0.0.1:3000 ($code)"; ready="yes"; break
            fi
            echo "Waiting for app... ($i/120) got $code"; sleep 2
          done
          if [ -z "$ready" ]; then
            echo "App failed to become ready. Tail of /tmp/app.log:"; tail -n 400 /tmp/app.log || true; exit 1
          fi
          # quick curls for e2e landing/sign-in pages
          curl -sS -D /tmp/home.headers http://127.0.0.1:3000/ -o /tmp/home.html || true
          curl -sS -D /tmp/login.headers http://127.0.0.1:3000/login -o /tmp/login.html || true
          tail -n 200 /tmp/app.log || true

      - name: Create WDIO CI config (trace logs + screenshots on fail)
        run: |
          cat > wdio.ci.conf.js <<'JS'
          const path = require('path');
          const os = require('os');
          const fs = require('fs');
          const basePath = path.resolve(__dirname, 'test/e2e.conf.js');
          const baseMod = require(basePath);
          const base = baseMod.config || baseMod;

          const profile = fs.mkdtempSync(path.join(os.tmpdir(), 'wdio-chrome-'));

          const ensureArgs = (c = {}) => {
            const opts = c['goog:chromeOptions'] || {};
            const args = new Set([...(opts.args || []),
              '--no-sandbox',
              '--disable-dev-shm-usage',
              '--window-size=1920,1080',
              `--user-data-dir=${profile}`,
              '--headless=new'
            ]);
            const out = {
              browserName: c.browserName || 'chrome',
              ...c,
              'goog:chromeOptions': { ...opts, args: Array.from(args) },
              'wdio:enforceWebDriverClassic': true
            };
            if (process.env.CHROME_BIN) out['goog:chromeOptions'].binary = process.env.CHROME_BIN;
            return out;
          };

          const caps = Array.isArray(base.capabilities)
            ? base.capabilities.map(ensureArgs)
            : [ensureArgs(base.capabilities || {})];

          const toAbs = (p, root) => (path.isAbsolute(p) ? p : path.join(root, p));
          const baseDir = path.dirname(basePath);
          const specs = (base.specs && base.specs.length ? base.specs : ['e2e/**/*.js','e2e/*.js'])
            .map(p => toAbs(p, baseDir));
          const exclude = (base.exclude || []).map(p => toAbs(p, baseDir));

          exports.config = {
            ...base,
            baseUrl: process.env.BASE_URL || base.baseUrl || 'http://127.0.0.1:3000',
            maxInstances: 1,
            capabilities: caps,
            specs,
            exclude,
            logLevel: 'trace',
            outputDir: './wdio-logs',
            reporters: (base.reporters || ['spec']),
            afterTest: async function (_test, _context, { passed }) {
              if (!passed) {
                const dir = path.resolve(__dirname, 'screenshots');
                if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true });
                try { await browser.saveScreenshot(path.join(dir, `${Date.now()}_fail.png`)); } catch (e) {}
              }
            }
          };
          JS

      - name: Pick one E2E spec
        id: pickspec
        run: |
          set -euo pipefail
          SPEC="${SPEC:-}"
          if [ -z "$SPEC" ]; then
            SPEC=$(ls -1 test/e2e/*.js test/e2e/**/*.js 2>/dev/null | head -n 1 || true)
          fi
          if [ -z "$SPEC" ]; then
            echo "No spec files found under test/e2e/"; exit 1
          fi
          echo "Running single spec: $SPEC"
          echo "spec=$SPEC" >> "$GITHUB_OUTPUT"

      - name: Pre-run diagnostics (WireMock + app)
        run: |
          set -euo pipefail
          mkdir -p diag
          curl -sS "$WIREMOCK_URL/__admin/mappings" > diag/wiremock_mappings.json || true
          curl -sS "$WIREMOCK_URL/__admin/requests/recent" > diag/wiremock_requests_pre.json || true
          curl -sS -D diag/app_home.headers "$BASE_URL/" -o diag/app_home.html || true
          curl -sS -D diag/app_login.headers "$BASE_URL/login" -o diag/app_login.html || true

      - name: DIAG capture end-to-end auth roundtrip (headers, cookies, WM mappings)
        run: |
          set -euo pipefail
          mkdir -p diag

          echo "=== ENV SNAPSHOT ===" > diag/env.txt
          env | sort >> diag/env.txt

          echo "=== APP / (no follow) ==="
          curl -s -I "$BASE_URL/" | tee diag/app_root.headers || true

          echo "=== APP / (follow, keep cookies) ==="
          curl -s -I -L -c diag/cookies1.txt -b diag/cookies1.txt "$BASE_URL/" | tee diag/app_root_follow.headers || true

          echo "=== WireMock settings ==="
          curl -s "$WIREMOCK_URL/__admin/settings" | jq . > diag/wm_settings.json || true

          echo "=== WireMock ALL mappings ==="
          curl -s "$WIREMOCK_URL/__admin/mappings" | jq . > diag/wm_mappings.json || true

          echo "=== WireMock authorize probe (with redirect_uri) ==="
          curl -s -i "$WIREMOCK_URL/auth/oauth/authorize?client_id=workload-measurement-ui&redirect_uri=${BASE_URL}/sign-in/callback&response_type=code&state=xyz" > diag/wm_authorize_probe.txt || true

          echo "=== WireMock token probe ==="
          curl -s -i -X POST "$WIREMOCK_URL/auth/oauth/token" > diag/wm_token_probe.txt || true

          echo "=== Cookie jars ===" > diag/cookies.dump
          echo "--- cookies1.txt ---" >> diag/cookies.dump
          cat diag/cookies1.txt >> diag/cookies.dump || true

          echo "=== APP / final (follow, save body) ==="
          curl -s -L -c diag/cookies2.txt -b diag/cookies2.txt "$BASE_URL/" -o diag/app_root_final.html || true
          wc -c diag/app_root_final.html | tee diag/app_root_final.size || true
          echo "--- cookies2.txt ---" >> diag/cookies.dump
          cat diag/cookies2.txt >> diag/cookies.dump || true

          echo "=== Sanity for callback route existence ==="
          # Try both common callback paths; the one your app really handles should 200/302, not 404
          curl -s -I "${BASE_URL}/sign-in/callback?code=test&state=s" | tee diag/app_callback_signin.headers || true
          curl -s -I "${BASE_URL}/login/callback?code=test&state=s"   | tee diag/app_callback_login.headers  || true

      - name: Upload DIAG artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-auth-diag
          path: diag
          if-no-files-found: warn


      - name: Run E2E (single spec; isolated Chrome profile)
        env:
          BASE_URL: ${{ env.BASE_URL }}
          DATABASE_SERVER: 127.0.0.1
          DATABASE_USERNAME: postgres
          DATABASE_PASSWORD: postgres
          DATABASE: postgres
          DATABASE_PORT: "5432"
          DATABASE_SSL: "false"
          CHROME_BIN: ${{ env.CHROME_BIN }}
        run: |
          set -euo pipefail
          export $(grep -v '^\s*#' feature.env | xargs)
          export BASE_URL="${BASE_URL}"
          npm run clean-dev-data
          npm run seed-dev-data
          pkill -f "chrome" || true
          npx wdio wdio.ci.conf.js --workers 1 --spec "${{ steps.pickspec.outputs.spec }}"
          npm run clean-dev-data

      - name: Post-run diagnostics (always)
        if: always()
        run: |
          set -euo pipefail
          mkdir -p diag
          echo "=== tail app.log ===" >> diag/app_tail.txt
          tail -n 400 /tmp/app.log >> diag/app_tail.txt || true
          echo "=== docker ps ===" > diag/docker_ps.txt
          docker ps -a >> diag/docker_ps.txt || true
          echo "=== wiremock requests (recent) ===" > diag/wiremock_requests_post.json
          curl -sS "$WIREMOCK_URL/__admin/requests/recent" >> diag/wiremock_requests_post.json || true

      - name: Upload E2E artifacts (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-artifacts-failure
          path: |
            ./screenshots
            ./videos
            ./wdio-*.log
            ./wdio-logs
            /tmp/app.log
            ./diag
          if-no-files-found: ignore

      - name: Upload minimal diagnostics (always)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-diag
          path: |
            ./wdio-logs
            ./diag
            /tmp/home.html
            /tmp/login.html
            /tmp/home.headers
            /tmp/login.headers
          if-no-files-found: ignore
