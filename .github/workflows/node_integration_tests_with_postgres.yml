name: Integration & E2E Tests

on:
  workflow_call:
    inputs:
      node_version_file:
        description: "setup-node reads Node version from here"
        required: false
        type: string
        default: ".nvmrc"

permissions:
  contents: read

jobs:
  integration-tests:
    name: integration tests
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U postgres -d postgres"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=20
      localstack:
        image: localstack/localstack:latest
        ports:
          - 4566:4566
        env:
          SERVICES: s3,sqs,sns
      wiremock:
        image: wiremock/wiremock:2.35.0
        ports:
          - 8099:8080
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379

    env:
      # AWS / endpoints
      AWS_DEFAULT_REGION: eu-west-2
      AWS_ACCESS_KEY_ID: foobar
      AWS_SECRET_ACCESS_KEY: foobar
      LS: http://localhost:4566

    steps:
      - uses: actions/checkout@v4

      - name: Wait for services
        run: |
          for i in {1..60}; do pg_isready -h 127.0.0.1 -p 5432 -U postgres -d postgres && break; sleep 1; done
          curl -sfS --retry 20 --retry-connrefused --retry-delay 2 "$LS/_localstack/health" || exit 1
          curl -sfS --retry 20 --retry-connrefused --retry-delay 2 "http://127.0.0.1:8099/__admin" || exit 1

      - name: Install jq & psql client
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq postgresql-client

      - name: Setup AWS CLI
        run: |
          python3 -m pip install --user --upgrade pip
          python3 -m pip install --user "awscli==1.*"
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"

      - name: Create sample dashboard file (used for uploads)
        run: |
          # exact content, no trailing newline
          printf 'dashboard' > dashboard-file.txt

      # ==== AWS population (mirrors your script) ====
      - name: Seed LocalStack (S3 + SQS)
        run: |
          set -euo pipefail
          # queue: audit_event_queue
          aws --endpoint-url="$LS" sqs create-queue --queue-name audit_event_queue || true

          # bucket: wmt-web + five objects under generated-dashboards/
          aws --endpoint-url="$LS" s3api create-bucket \
            --bucket wmt-web \
            --region "$AWS_DEFAULT_REGION" \
            --create-bucket-configuration LocationConstraint="$AWS_DEFAULT_REGION" || true

          for ts in 20210729062147 20210730062147 20210731062147 20210801062147 20210802062147; do
            aws --endpoint-url="$LS" s3api put-object \
              --bucket wmt-web \
              --key generated-dashboards/dashboard_${ts}.txt \
              --body dashboard-file.txt
          done

      # (kept from your previous flow) start workload container and wait for schema
      - name: Start hmpps_workload container
        run: |
          docker run -d --name hmpps_workload \
            --add-host=host.docker.internal:host-gateway \
            -e SPRING_PROFILES_ACTIVE=dev,docker \
            -e DATABASE_USERNAME=postgres \
            -e DATABASE_PASSWORD=postgres \
            -e DATABASE_ENDPOINT=host.docker.internal:5432 \
            -e HMPPS_SQS_LOCALSTACK_URL=http://host.docker.internal:4566 \
            ghcr.io/ministryofjustice/hmpps-workload:latest \
            /bin/sh -lc 'sleep 10 && java -javaagent:/app/agent.jar -jar /app/app.jar'

      - name: Wait for DB schema
        env:
          PGPASSWORD: postgres
        run: |
          for i in {1..120}; do
            psql -h 127.0.0.1 -U postgres -d postgres -tAc "SELECT 1 FROM information_schema.tables WHERE table_name='flyway_schema_history'" | grep -q 1 && exit 0
            sleep 2
          done
          echo "Schema not ready in time"; docker logs hmpps_workload || true; exit 1

      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: .nvmrc

      - name: Install deps
        run: npm ci --no-audit

      - name: Run integration tests
        env:
          DATABASE_SERVER: localhost
          DATABASE_USERNAME: postgres
          DATABASE_PASSWORD: postgres
          DATABASE: postgres
          DATABASE_PORT: "5432"
          DATABASE_SSL: "false"
        run: npm run integration-test

  e2e-tests:
    name: e2e tests
    needs: integration-tests
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports:
          - 5432:5432
        options: >-
          --health-cmd="pg_isready -U postgres -d postgres"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=20
      localstack:
        image: localstack/localstack:latest
        ports:
          - 4566:4566
        env:
          SERVICES: s3,sqs,sns
      wiremock:
        image: wiremock/wiremock:2.35.0
        ports:
          - 8099:8080
        options: >-
          --mount type=bind,source=${{ github.workspace }}/test/e2e/resources/wiremock/mappings,target=/home/wiremock/mappings,readonly
          --mount type=bind,source=${{ github.workspace }}/test/e2e/resources/wiremock/__files,target=/home/wiremock/__files,readonly
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379

    env:
      AWS_DEFAULT_REGION: eu-west-2
      AWS_ACCESS_KEY_ID: foobar
      AWS_SECRET_ACCESS_KEY: foobar
      LS: http://localhost:4566

      APP_PORT: "3000"
      BASE_URL: http://localhost:3000
      WIREMOCK_URL: http://localhost:8099
      CHROME_BIN: /usr/bin/google-chrome

    steps:
      - uses: actions/checkout@v4

      - name: Wait for services
        run: |
          for i in {1..60}; do pg_isready -h 127.0.0.1 -p 5432 -U postgres -d postgres && break; sleep 1; done
          curl -sfS --retry 30 --retry-connrefused --retry-delay 2 "$LS/_localstack/health" || exit 1
          curl -sfS --retry 30 --retry-connrefused --retry-delay 2 "http://localhost:8099/__admin" || exit 1

      - name: Setup AWS CLI + jq
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq
          python3 -m pip install --user --upgrade pip
          python3 -m pip install --user "awscli==1.*"
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"

      - name: Seed LocalStack (queue + sample dashboards)
        run: |
          set -euo pipefail
          aws --endpoint-url="$LS" sqs create-queue --queue-name audit_event_queue || true
          aws --endpoint-url="$LS" s3api create-bucket \
            --bucket wmt-web \
            --region "$AWS_DEFAULT_REGION" \
            --create-bucket-configuration LocationConstraint="$AWS_DEFAULT_REGION" || true
          printf 'dashboard' > dashboard-file.txt
          for ts in 20210729062147 20210730062147 20210731062147 20210801062147 20210802062147; do
            aws --endpoint-url="$LS" s3api put-object \
              --bucket wmt-web \
              --key generated-dashboards/dashboard_${ts}.txt \
              --body dashboard-file.txt
          done

      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: .nvmrc

      - name: Install deps
        run: npm ci --no-audit

      - name: Install Google Chrome (for WDIO)
        run: |
          set -euo pipefail
          sudo apt-get update
          sudo apt-get install -y wget gpg
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo gpg --dearmor -o /usr/share/keyrings/google-linux-signing-keyring.gpg
          echo "deb [arch=amd64 signed-by=/usr/share/keyrings/google-linux-signing-keyring.gpg] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list >/dev/null
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          google-chrome --version

      - name: Install psql client
        run: |
          sudo apt-get update -y
          sudo apt-get install -y postgresql-client

      - name: Start hmpps_workload container
        run: |
          docker run -d --name hmpps_workload \
            --add-host=host.docker.internal:host-gateway \
            -e SPRING_PROFILES_ACTIVE=dev,docker \
            -e DATABASE_USERNAME=postgres \
            -e DATABASE_PASSWORD=postgres \
            -e DATABASE_ENDPOINT=host.docker.internal:5432 \
            -e HMPPS_SQS_LOCALSTACK_URL=http://host.docker.internal:4566 \
            ghcr.io/ministryofjustice/hmpps-workload:latest \
            /bin/sh -lc 'sleep 10 && java -javaagent:/app/agent.jar -jar /app/app.jar'

      - name: Wait for DB schema
        env:
          PGPASSWORD: postgres
        run: |
          for i in {1..120}; do
            psql -h 127.0.0.1 -U postgres -d postgres -tAc "SELECT 1 FROM information_schema.tables WHERE table_name='flyway_schema_history'" | grep -q 1 && exit 0
            echo "Waiting for Flyway schema... ($i/120)"
            sleep 2
          done
          echo "Schema not ready in time"; docker logs hmpps_workload || true; exit 1

      - name: Build assets
        run: npm run build

      - name: Start app (start-dev on :3000)
        env:
          WMT_LIVE_DB_SERVER: localhost
          WMT_LIVE_DB_NAME: postgres
          WMT_LIVE_DB_USERNAME: postgres
          WMT_LIVE_DB_PASSWORD: postgres
          WMT_HISTORY_DB_SERVER: localhost
          WMT_HISTORY_DB_PORT: "5432"
          WMT_HISTORY_DB_NAME: postgres
          WMT_HISTORY_DB_USERNAME: postgres
          WMT_HISTORY_DB_PASSWORD: postgres
          PORT: 3000
          REDIS_HOST: localhost
          REDIS_PORT: "6379"
          REDIS_URL: redis://localhost:6379
          HMPPS_AUTH_URL: http://localhost:8099/auth
          HMPPS_AUTH_EXTERNAL_URL: http://localhost:8099/auth
          MANAGE_USERS_SERVICE_URL: http://localhost:8099
          ALLOCATIONS_SERVICE_URL: http://localhost:8099
          USER_PREFERENCE_SERVICE_URL: http://localhost:8099
          TOKEN_VERIFICATION_API_URL: http://localhost:8099
        run: |
          set -euo pipefail
          # Feature env + our overrides (so we don’t lose your other vars)
          nohup env $(cat feature.env | xargs) \
            PORT=$PORT \
            WMT_LIVE_DB_SERVER=$WMT_LIVE_DB_SERVER WMT_LIVE_DB_NAME=$WMT_LIVE_DB_NAME WMT_LIVE_DB_USERNAME=$WMT_LIVE_DB_USERNAME WMT_LIVE_DB_PASSWORD=$WMT_LIVE_DB_PASSWORD \
            WMT_HISTORY_DB_SERVER=$WMT_HISTORY_DB_SERVER WMT_HISTORY_DB_PORT=$WMT_HISTORY_DB_PORT WMT_HISTORY_DB_NAME=$WMT_HISTORY_DB_NAME WMT_HISTORY_DB_USERNAME=$WMT_HISTORY_DB_USERNAME WMT_HISTORY_DB_PASSWORD=$WMT_HISTORY_DB_PASSWORD \
            REDIS_HOST=$REDIS_HOST REDIS_PORT=$REDIS_PORT REDIS_URL=$REDIS_URL \
            HMPPS_AUTH_URL=$HMPPS_AUTH_URL HMPPS_AUTH_EXTERNAL_URL=$HMPPS_AUTH_EXTERNAL_URL MANAGE_USERS_SERVICE_URL=$MANAGE_USERS_SERVICE_URL \
            ALLOCATIONS_SERVICE_URL=$ALLOCATIONS_SERVICE_URL USER_PREFERENCE_SERVICE_URL=$USER_PREFERENCE_SERVICE_URL TOKEN_VERIFICATION_API_URL=$TOKEN_VERIFICATION_API_URL \
            node app/bin/www >/tmp/app.log 2>&1 &
          for i in {1..60}; do
            code=$(curl -fsS -o /dev/null -w "%{http_code}" "http://localhost:3000/")
            if echo "$code" | grep -qE '200|302'; then
            echo "App ready at http://localhost:3000 (${code})"
            break
            fi
            echo "Waiting for app... ($i/60)"
            sleep 2
          done
          echo '--- app log tail ---'
          tail -n 200 /tmp/app.log || true

      - name: Load WireMock mappings
        run: npm run post-wiremock-mappings

      - name: Create WDIO CI config (unique Chrome profile + absolute specs)
        run: |
          cat > wdio.ci.conf.js <<'JS'
          const path = require('path');
          const os = require('os');
          const fs = require('fs');
          const basePath = path.resolve(__dirname, 'test/e2e.conf.js');
          const baseMod = require(basePath);
          const base = baseMod.config || baseMod;

          const profile = fs.mkdtempSync(path.join(os.tmpdir(), 'wdio-chrome-'));

          const ensureArgs = (c = {}) => {
            const opts = c['goog:chromeOptions'] || {};
            const args = new Set([...(opts.args || []),
              '--no-sandbox',
              '--disable-dev-shm-usage',
              `--user-data-dir=${profile}`,
              '--headless=new'
            ]);
            const out = {
              browserName: c.browserName || 'chrome',
              ...c,
              'goog:chromeOptions': { ...opts, args: Array.from(args) },
              'wdio:enforceWebDriverClassic': true
            };
            if (process.env.CHROME_BIN) {
              out['goog:chromeOptions'].binary = process.env.CHROME_BIN;
            }
            return out;
          };

          const caps = Array.isArray(base.capabilities)
            ? base.capabilities.map(ensureArgs)
            : [ensureArgs(base.capabilities || {})];

          // Make specs absolute so moving the config file doesn't break glob resolution
          const baseDir = path.dirname(basePath);
          const toAbs = (p) => path.isAbsolute(p) ? p : path.join(baseDir, p);
          const specs = (base.specs && base.specs.length ? base.specs : ['e2e/**/*.js','e2e/*.js'])
            .map(toAbs);
          const exclude = (base.exclude || []).map(toAbs);

          exports.config = { ...base, specs, exclude, maxInstances: 1, capabilities: caps };
          JS

      - name: Run E2E (wdio with isolated Chrome profile)
        env:
          BASE_URL: ${{ env.BASE_URL }}
          DATABASE_SERVER: localhost
          DATABASE_USERNAME: postgres
          DATABASE_PASSWORD: postgres
          DATABASE: postgres
          DATABASE_PORT: "5432"
          DATABASE_SSL: "false"
          CHROME_BIN: ${{ env.CHROME_BIN }}
        run: |
          set -euo pipefail
          export $(cat feature.env | xargs)
          npm run clean-dev-data
          npm run seed-dev-data
          pkill -f "chrome" || true
          npx wdio wdio.ci.conf.js --workers 1
          npm run clean-dev-data

      - name: Upload E2E artifacts (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-artifacts
          path: |
            ./screenshots
            ./videos
            ./wdio-*.log
          if-no-files-found: ignore
