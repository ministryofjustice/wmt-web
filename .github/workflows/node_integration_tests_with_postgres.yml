name: Integration & E2E Tests

on:
  workflow_call:
    inputs:
      node_version_file:
        description: "setup-node reads Node version from here"
        required: false
        type: string
        default: ".nvmrc"

permissions:
  contents: read

jobs:
  integration-tests:
    name: integration tests
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports: [ "5432:5432" ]
        options: >-
          --health-cmd="pg_isready -U postgres -d postgres"
          --health-interval=5s --health-timeout=5s --health-retries=20
      localstack:
        image: localstack/localstack:latest
        ports: [ "4566:4566" ]
        env:
          SERVICES: s3,sqs,sns
      redis:
        image: redis:7-alpine
        ports: [ "6379:6379" ]

    env:
      AWS_DEFAULT_REGION: eu-west-2
      AWS_ACCESS_KEY_ID: foobar
      AWS_SECRET_ACCESS_KEY: foobar
      LS: http://127.0.0.1:4566

    steps:
      - uses: actions/checkout@v4

      - name: Start WireMock (global response templating)
        run: |
          docker run -d --name wiremock-ci \
            -p 8099:8080 \
            wiremock/wiremock:2.35.0 \
            --port 8080 --global-response-templating
          # wait until ready
          for i in {1..30}; do
            curl -fsS "http://127.0.0.1:8099/__admin" >/dev/null && break
            echo "Waiting for WireMock... ($i/30)"; sleep 2
          done
          # quick proof that templating is ON (this endpoint exists in v2.35 but doesn't reflect global flag,
          # so we'll do a live render check right after mappings are loaded)

      - name: Wait for services
        run: |
          for i in {1..60}; do pg_isready -h 127.0.0.1 -p 5432 -U postgres -d postgres && break; sleep 1; done
          curl -sfS --retry 20 --retry-connrefused --retry-delay 2 "$LS/_localstack/health" || exit 1
          curl -sfS --retry 20 --retry-connrefused --retry-delay 2 "http://127.0.0.1:8099/__admin" || exit 1
          for i in {1..60}; do (echo > /dev/tcp/127.0.0.1/6379) >/dev/null 2>&1 && break; sleep 1; done

      - name: Install jq & psql client
        run: |
          sudo apt-get update -y
          sudo apt-get install -y jq postgresql-client

      - name: Setup AWS CLI
        run: |
          python3 -m pip install --user --upgrade pip
          python3 -m pip install --user "awscli==1.*"
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"

      - name: Create sample dashboard file (used for uploads)
        run: printf 'dashboard' > dashboard-file.txt

      - name: Seed LocalStack (S3 + SQS)
        run: |
          set -euo pipefail
          aws --endpoint-url="$LS" sqs create-queue --queue-name audit_event_queue || true
          aws --endpoint-url="$LS" s3api create-bucket \
            --bucket wmt-web \
            --region "$AWS_DEFAULT_REGION" \
            --create-bucket-configuration LocationConstraint="$AWS_DEFAULT_REGION" || true
          for ts in 20210729062147 20210730062147 20210801062147 20210802062147; do
            aws --endpoint-url="$LS" s3api put-object \
              --bucket wmt-web \
              --key generated-dashboards/dashboard_${ts}.txt \
              --body dashboard-file.txt
          done

      - name: Start hmpps_workload container
        run: |
          docker run -d --name hmpps_workload \
            --add-host=host.docker.internal:host-gateway \
            -e SPRING_PROFILES_ACTIVE=dev,docker \
            -e DATABASE_USERNAME=postgres \
            -e DATABASE_PASSWORD=postgres \
            -e DATABASE_ENDPOINT=host.docker.internal:5432 \
            -e HMPPS_SQS_LOCALSTACK_URL=http://host.docker.internal:4566 \
            ghcr.io/ministryofjustice/hmpps-workload:latest \
            /bin/sh -lc 'sleep 10 && java -javaagent:/app/agent.jar -jar /app/app.jar'

      - name: Wait for DB schema
        env: { PGPASSWORD: postgres }
        run: |
          for i in {1..120}; do
            psql -h 127.0.0.1 -U postgres -d postgres -tAc \
              "SELECT 1 FROM information_schema.tables WHERE table_name='flyway_schema_history'" | grep -q 1 && exit 0
            sleep 2
          done
          echo "Schema not ready in time"; docker logs hmpps_workload || true; exit 1

      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: ${{ inputs.node_version_file }}

      - name: Install deps
        run: npm ci --no-audit

      - name: Run integration tests
        env:
          DATABASE_SERVER: 127.0.0.1
          DATABASE_USERNAME: postgres
          DATABASE_PASSWORD: postgres
          DATABASE: postgres
          DATABASE_PORT: "5432"
          DATABASE_SSL: "false"
        run: npm run integration-test

  e2e-tests:
    name: e2e tests
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: postgres
          POSTGRES_PASSWORD: postgres
        ports: [ "5432:5432" ]
        options: >-
          --health-cmd="pg_isready -U postgres -d postgres"
          --health-interval=5s --health-timeout=5s --health-retries=20

      localstack:
        image: localstack/localstack:latest
        ports: [ "4566:4566" ]
        env:
          SERVICES: s3,sqs,sns

      redis:
        image: redis:7-alpine
        ports: [ "6379:6379" ]

      hmpps-manage-users-api:
        image: quay.io/hmpps/hmpps-manage-users-api:latest
        ports: [ "9091:9091" ]
        env:
          SPRING_PROFILES_ACTIVE: dev,delius
          DELIUS_ENABLED: "true"
          SERVER_PORT: "9091"
          MANAGE_USERS_API_ENABLED: "true"
        options: >-
          --health-cmd="curl -fsS http://localhost:9091/health/ping || exit 1"
          --health-interval=5s --health-timeout=5s --health-retries=50

      hmpps-auth:
        image: quay.io/hmpps/hmpps-auth:latest
        ports: [ "9090:9090" ]
        env:
          SPRING_PROFILES_ACTIVE: dev,delius
          DELIUS_ENABLED: "true"
          SERVER_PORT: "9090"
          MANAGE_USERS_API_ENABLED: "true"
          MANAGE_USERS_API_ENDPOINT_URL: http://hmpps-manage-users-api:9091
        options: >-
          --health-cmd="curl -fsS http://localhost:9090/health/ping || curl -fsS http://localhost:9090/auth/health/ping || exit 1"
          --health-interval=5s --health-timeout=5s --health-retries=60

    env:
      AWS_DEFAULT_REGION: eu-west-2
      AWS_ACCESS_KEY_ID: foobar
      AWS_SECRET_ACCESS_KEY: foobar
      LS: http://127.0.0.1:4566

      APP_PORT: "3000"
      BASE_URL: http://127.0.0.1:3000
      WIREMOCK_URL: http://127.0.0.1:8099
      CHROME_BIN: /usr/bin/google-chrome
      WDIO_LOG_LEVEL: debug

    steps:
      - uses: actions/checkout@v4

      # Start WireMock (separately so we can curl __admin and POST mappings)
      - name: Start WireMock (global response templating)
        run: |
          set -euxo pipefail
          docker run -d --name wiremock-ci -p 8099:8080 wiremock/wiremock:2.35.0 \
            --port 8080 --global-response-templating
          for i in {1..60}; do
            curl -fsS "http://127.0.0.1:8099/__admin" >/dev/null && break
            echo "Waiting for WireMock... ($i/60)"; sleep 2
          done
          curl -s "http://127.0.0.1:8099/__admin" | head -c 400 || true

      - name: Wait for platform services (robust, with logs on failure)
        run: |
          set -euxo pipefail

          probe () {
            local name="$1" url="$2" tries="${3:-60}"
            echo "Probing $name at $url"
            for i in $(seq 1 "$tries"); do
              code=$(curl -sS -o /dev/null -w '%{http_code}' --connect-timeout 5 --max-time 10 "$url" || echo "000")
              if [ "$code" = "200" ]; then echo "$name is up (200)"; return 0; fi
              echo "[$i/$tries] $name not ready (code=$code); sleeping..."; sleep 2
            done
            echo "$name failed to become healthy after $tries attempts"; return 1
          }

          # Core infra
          for i in {1..60}; do pg_isready -h 127.0.0.1 -p 5432 -U postgres -d postgres && break; sleep 1; done
          curl -fsS --retry 60 --retry-connrefused --retry-delay 2 "$LS/_localstack/health" >/dev/null
          for i in {1..60}; do (echo > /dev/tcp/127.0.0.1/6379) >/dev/null 2>&1 && break; sleep 1; done

          # App deps
          set +e
          probe "manage-users" "http://127.0.0.1:9091/health/ping" 90 || MU_FAIL=1
          probe "hmpps-auth (/health/ping)" "http://127.0.0.1:9090/health/ping" 120 || AUTH_DIRECT_FAIL=1
          if [ "${AUTH_DIRECT_FAIL:-}" = "1" ]; then
            probe "hmpps-auth (/auth/health/ping)" "http://127.0.0.1:9090/auth/health/ping" 30 || AUTH_FAIL=1
          fi
          set -e

          if [ "${MU_FAIL:-0}" = "1" ] || [ "${AUTH_FAIL:-0}" = "1" ] || [ "${AUTH_DIRECT_FAIL:-0}" = "1" ]; then
            echo "=== Container list ==="; docker ps
            echo "=== hmpps-auth logs ==="
            docker logs "$(docker ps -q --filter "ancestor=quay.io/hmpps/hmpps-auth:latest" | head -n1)" || true
            echo "=== manage-users logs ==="
            docker logs "$(docker ps -q --filter "ancestor=quay.io/hmpps/hmpps-manage-users-api:latest" | head -n1)" || true
            exit 1
          fi

          # Sanity peek at WireMock admin
          curl -fsS "http://127.0.0.1:8099/__admin" | head -c 400 || true

      - name: Setup AWS CLI + jq
        run: |
          set -euxo pipefail
          sudo apt-get update -y
          sudo apt-get install -y jq
          python3 -m pip install --user --upgrade pip
          python3 -m pip install --user "awscli==1.*"
          echo "$HOME/.local/bin" >> "$GITHUB_PATH"

      - name: Seed LocalStack (queue + sample dashboards)
        run: |
          set -euxo pipefail
          aws --endpoint-url="$LS" sqs create-queue --queue-name audit_event_queue || true
          aws --endpoint-url="$LS" s3api create-bucket \
            --bucket wmt-web \
            --region "$AWS_DEFAULT_REGION" \
            --create-bucket-configuration LocationConstraint="$AWS_DEFAULT_REGION" || true
          printf 'dashboard' > dashboard-file.txt
          for ts in 20210729062147 20210730062147 20210801062147 20210802062147; do
            aws --endpoint-url="$LS" s3api put-object \
              --bucket wmt-web \
              --key generated-dashboards/dashboard_${ts}.txt \
              --body dashboard-file.txt
          done

      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version-file: ${{ inputs.node_version_file }}

      - name: Install deps
        run: npm ci --no-audit

      - name: Install Google Chrome (for WDIO)
        run: |
          set -euxo pipefail
          sudo apt-get update
          sudo apt-get install -y wget gpg
          wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | sudo gpg --dearmor -o /usr/share/keyrings/google-linux-signing-keyring.gpg
          echo "deb [arch=amd64 signed-by=/usr/share/keyrings/google-linux-signing-keyring.gpg] http://dl.google.com/linux/chrome/deb/ stable main" | sudo tee /etc/apt/sources.list.d/google-chrome.list >/dev/null
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
          google-chrome --version

      - name: Install psql client
        run: |
          sudo apt-get update -y
          sudo apt-get install -y postgresql-client

      - name: Start hmpps_workload container
        run: |
          set -euxo pipefail
          docker run -d --name hmpps_workload \
            --add-host=host.docker.internal:host-gateway \
            -e SPRING_PROFILES_ACTIVE=dev,docker \
            -e DATABASE_USERNAME=postgres \
            -e DATABASE_PASSWORD=postgres \
            -e DATABASE_ENDPOINT=host.docker.internal:5432 \
            -e HMPPS_SQS_LOCALSTACK_URL=http://host.docker.internal:4566 \
            ghcr.io/ministryofjustice/hmpps-workload:latest \
            /bin/sh -lc 'sleep 10 && java -javaagent:/app/agent.jar -jar /app/app.jar'

      - name: Wait for DB schema
        env: { PGPASSWORD: postgres }
        run: |
          set -euxo pipefail
          for i in {1..120}; do
            psql -h 127.0.0.1 -U postgres -d postgres -tAc \
              "SELECT 1 FROM information_schema.tables WHERE table_name='flyway_schema_history'" | grep -q 1 && exit 0
            echo "Waiting for Flyway schema... ($i/120)"; sleep 2
          done
          echo "Schema not ready in time"; docker logs hmpps_workload || true; exit 1

      - name: Build assets
        run: npm run build

      - name: Start app (direct)
        env:
          WMT_WEB_APPLICATION_SECRET: ci-dev-secret
          SESSION_SECRET: ci-session-secret
          WMT_LIVE_DB_SERVER: 127.0.0.1
          WMT_LIVE_DB_NAME: postgres
          WMT_LIVE_DB_USERNAME: postgres
          WMT_LIVE_DB_PASSWORD: postgres
          WMT_HISTORY_DB_SERVER: 127.0.0.1
          WMT_HISTORY_DB_PORT: "5432"
          WMT_HISTORY_DB_NAME: postgres
          WMT_HISTORY_DB_USERNAME: postgres
          WMT_HISTORY_DB_PASSWORD: postgres
          REDIS_HOST: 127.0.0.1
          REDIS_PORT: "6379"
          REDIS_URL: redis://127.0.0.1:6379
          # Real auth + manage users
          HMPPS_AUTH_URL: http://127.0.0.1:9090/auth
          HMPPS_AUTH_EXTERNAL_URL: http://127.0.0.1:9090/auth
          MANAGE_USERS_SERVICE_URL: http://127.0.0.1:9091
          # Everything else via WireMock
          ALLOCATIONS_SERVICE_URL: http://127.0.0.1:8099
          USER_PREFERENCE_SERVICE_URL: http://127.0.0.1:8099
          TOKEN_VERIFICATION_API_URL: http://127.0.0.1:8099
          TOKEN_VERIFICATION_ENABLED: "true"
          INGRESS_URL: http://127.0.0.1:3000
          PORT: 3000
        run: |
          set -euxo pipefail
          export $(grep -v '^\s*#' feature.env | xargs) || true
          nohup node app/bin/www > /tmp/app.log 2>&1 &
          for i in {1..120}; do
            code=$(curl -s -o /dev/null -w "%{http_code}" "http://127.0.0.1:3000/" || echo "000")
            if [ "$code" = "200" ] || [ "$code" = "302" ]; then
              echo "App ready at http://127.0.0.1:3000 ($code)"; break
            fi
            echo "Waiting for app... ($i/120)"; sleep 2
          done
          tail -n 200 /tmp/app.log || true

      - name: Load WireMock mappings from repo
        run: npm run post-wiremock-mappings

      # (No auth override here; weâ€™re using real hmpps-auth)

      - name: Create WDIO CI config (single worker, headless)
        run: |
          cat > wdio.ci.conf.js <<'JS'
          const path = require('path');
          const os = require('os');
          const fs = require('fs');
          const basePath = path.resolve(__dirname, 'test/e2e.conf.js');
          const baseMod = require(basePath);
          const base = baseMod.config || baseMod;

          const profile = fs.mkdtempSync(path.join(os.tmpdir(), 'wdio-chrome-'));
          const ensureArgs = (c = {}) => {
            const opts = c['goog:chromeOptions'] || {};
            const args = new Set([...(opts.args || []),
              '--no-sandbox','--disable-dev-shm-usage','--window-size=1920,1080',
              `--user-data-dir=${profile}`,'--headless=new'
            ]);
            const out = { browserName: c.browserName || 'chrome', ...c,
              'goog:chromeOptions': { ...opts, args: Array.from(args) },
              'wdio:enforceWebDriverClassic': true
            };
            if (process.env.CHROME_BIN) out['goog:chromeOptions'].binary = process.env.CHROME_BIN;
            return out;
          };

          const caps = Array.isArray(base.capabilities)
            ? base.capabilities.map(ensureArgs)
            : [ensureArgs(base.capabilities || {})];

          const toAbs = (p, root) => (path.isAbsolute(p) ? p : path.join(root, p));
          const baseDir = path.dirname(basePath);
          const specs = (base.specs && base.specs.length ? base.specs : ['e2e/**/*.js','e2e/*.js'])
            .map(p => toAbs(p, baseDir));
          const exclude = (base.exclude || []).map(p => toAbs(p, baseDir));

          exports.config = { ...base,
            baseUrl: process.env.BASE_URL || base.baseUrl || 'http://127.0.0.1:3000',
            maxInstances: 1, capabilities: caps, specs, exclude,
            logLevel: process.env.WDIO_LOG_LEVEL || 'info', outputDir: './wdio-logs'
          };
          JS

      - name: Pick one E2E spec
        id: pickspec
        run: |
          set -euxo pipefail
          SPEC="${SPEC:-}"
          if [ -z "$SPEC" ]; then
            SPEC=$(ls -1 test/e2e/*.js test/e2e/**/*.js 2>/dev/null | head -n 1 || true)
          fi
          [ -n "$SPEC" ] || { echo "No spec files in test/e2e/"; exit 1; }
          echo "Running single spec: $SPEC"
          echo "spec=$SPEC" >> "$GITHUB_OUTPUT"

      - name: Run E2E (single spec)
        env:
          BASE_URL: ${{ env.BASE_URL }}
          DATABASE_SERVER: 127.0.0.1
          DATABASE_USERNAME: postgres
          DATABASE_PASSWORD: postgres
          DATABASE: postgres
          DATABASE_PORT: "5432"
          DATABASE_SSL: "false"
          CHROME_BIN: ${{ env.CHROME_BIN }}
        run: |
          set -euxo pipefail
          export $(grep -v '^\s*#' feature.env | xargs) || true
          export BASE_URL="${BASE_URL}"
          npm run clean-dev-data
          npm run seed-dev-data
          pkill -f "chrome" || true
          npx wdio wdio.ci.conf.js --workers 1 --spec "${{ steps.pickspec.outputs.spec }}"
          npm run clean-dev-data

      - name: Upload E2E artifacts (on failure)
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-artifacts-failure
          path: |
            ./screenshots
            ./videos
            ./wdio-*.log
            ./wdio-logs
            /tmp/app.log
          if-no-files-found: ignore
